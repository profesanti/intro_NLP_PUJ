{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a la ingeniería de prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install groq\n",
    "# pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(\"/home/santi/Repos/.env\")\n",
    "\n",
    "# groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar la siguiente celda en colab, tras haber creado un secreto con el nombre de `GROQ_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En Colab crear un Secreto con el nombre de GROQ_API_KEY \n",
    "from google.colab import userdata\n",
    "groq_api_key = userdata.get('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es un Modelo de Lenguaje Grande?\n",
    "\n",
    "Estamos rodeados de IA en estos días. Vamos a la fuente: ¿Qué dijo **ChatGPT** cuando se le preguntó \"¿Qué es un modelo de lenguaje?\"\n",
    "\n",
    "| Tú | ChatGPT |\n",
    "| :------------------------------ | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| ¿Qué es un modelo de lenguaje? | Un modelo de lenguaje es un tipo de sistema de inteligencia artificial que se entrena para entender y generar texto similar al humano. Aprende la estructura, gramática y semántica de un idioma procesando grandes cantidades de datos textuales. El objetivo principal de un modelo de lenguaje es predecir la probabilidad de la siguiente palabra o secuencia de palabras en un contexto dado. |\n",
    "\n",
    "Eso es cierto, hasta donde llega. Pero la parte realmente interesante de la respuesta está oculta en la palabra **\"grande.\"** El tamaño masivo de los modelos de lenguaje grandes es lo que ha impulsado la ola actual de progreso en este espacio. Para entender qué hace que estos modelos sean tan poderosos y cómo han evolucionado en los últimos años, hagamos un breve recorrido por la historia:\n",
    "\n",
    "### Contexto Histórico de los Modelos de Lenguaje Grandes\n",
    "\n",
    "* Alrededor de 2014, las **Recurrent Neural Networks (RNNs)** con una arquitectura de codificador-decodificador eran el estado del arte. Sin embargo, sufrían de un **cuello de botella informacional** entre estas dos etapas, limitando su capacidad para procesar secuencias largas de texto de manera efectiva. ¡Imagina tratar de recordar todo un párrafo después de leerlo solo una vez!\n",
    "\n",
    "* En septiembre de 2014, el artículo *Neural Machine Translation by Jointly Learning to Align and Translate* introdujo el **Attention Mechanism**. Esto abordó el cuello de botella al permitir que el modelo \"buscara suavemente\" y se enfocara en la información más relevante de las etapas anteriores, en lugar de tratar de meter todo en una memoria limitada. Piensa en ello como resaltar los puntos clave en un documento largo.\n",
    "\n",
    "* Esta innovación llevó a un cambio dramático en el campo. Para junio de 2017, los investigadores abandonaron las RNNs por completo porque, como decía el título de un artículo revolucionario, *Attention Is All You Need*. Este trabajo introdujo la **Transformer Architecture**, que resultó ser aún más poderosa para una amplia gama de tareas de NLP, y sigue siendo la base de muchos LLMs hoy en día.\n",
    "\n",
    "* En junio de 2018, los investigadores refinaron aún más el Transformer con una técnica llamada *Improving Language Understanding by Generative Pre-Training*. Descubrieron que al \"cortar el Transformer por la mitad\" y usar solo el decodificador, podían crear un modelo que era notablemente efectivo en predecir la siguiente palabra en una secuencia. Este fue el nacimiento de **GPT-1 (Generative Pre-trained Transformer)**.\n",
    "\n",
    "* Solo unos meses después, en febrero de 2019, **GPT-2** (*Language Models are Unsupervised Multitask Learners*) fue lanzado al mundo. Entrenado en un conjunto de datos diez veces más grande que su predecesor, GPT-2 mostró una capacidad asombrosa para realizar bien una variedad de tareas de NLP *sin* ningún ajuste específico. Este fue un momento decisivo: sugirió que simplemente entrenar un modelo de lenguaje en un conjunto de datos masivo podría desbloquear capacidades sorprendentes y potencialmente peligrosas.\n",
    "\n",
    "\n",
    "| Fecha | Evento | Observación | Modelo |\n",
    "| :--------- | :------------------------------------------------------------------------------------------------------------------ | :----------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------- |\n",
    "| c. 2014 | Las Recurrent Neural Networks dominaban las tareas de NLP. | El principal problema de estos modelos era un cuello de botella informacional que ocurría entre el codificador y el decodificador | |\n",
    "| Sept 2014 | **Attention Mechanism** introducido en *Neural Machine Translation by Jointly Learning to Align and Translate*. | Este modelo usaba \"soft search\" para permitir un uso más eficiente de la información de contexto. | |\n",
    "| Jun 2017 | Los investigadores abandonan las RNNs porque *Attention Is All You Need*. | Esto introdujo la **Transformer** architecture, que resultó ser más poderosa en muchas tareas de NLP y sigue siendo utilizada hoy en día. | |\n",
    "| Jun 2018 | El Transformer se corta por la mitad usando la técnica *Improving Language Understanding by Generative Pre-Training*. | Solo se usa el decodificador del transformer en este caso. | **GPT-1** |\n",
    "| Feb 2019 | **GPT-2** (*Language Models are Unsupervised Multitask Learners*) es entrenado en 10 veces la cantidad de datos de **GPT-1**. | En este punto, los investigadores encontraron que la **Generative Pre-Training** de modelos de lenguaje sin ajuste fino estaba produciendo resultados sorprendentes en múltiples tareas de NLP. | **GPT-2** |\n",
    "\n",
    "Aquí tienes una muestra de lo que GPT-2 podía hacer:\n",
    "\n",
    "| | |\n",
    "| :------- | :------- |\n",
    "| Missing word prediction | Summarization |\n",
    "| Pronoun understanding | Sentiment analysis |\n",
    "| Part of speech tagging | Entity extraction |\n",
    "| Text compression | Question answering |\n",
    "| | Translation |\n",
    "| | Content generation |\n",
    "\n",
    "Recuerda, logró todo esto *sin* estar específicamente entrenado para ninguna de estas tareas. Esto fue tanto emocionante como alarmante. Como los propios creadores escribieron en el artículo de lanzamiento de GPT-2:\n",
    "\n",
    "> \"*Nuestro modelo, llamado GPT-2 (un sucesor de GPT), fue entrenado simplemente para predecir la siguiente palabra en 40GB de texto de Internet. **Debido a nuestras preocupaciones sobre aplicaciones maliciosas de la tecnología, no estamos liberando el modelo entrenado.** (ref)*\"\n",
    "\n",
    "Esas preocupaciones eran muy reales. La capacidad de GPT-2 para generar texto que suena plausible planteó el espectro de un futuro inundado con:\n",
    "\n",
    "* Artículos de noticias engañosos disfrazados de periodismo legítimo\n",
    "* Suplantación de identidad y fraude en línea a gran escala\n",
    "* Discurso de odio automatizado y propaganda en redes sociales\n",
    "* Campañas sofisticadas de spam y phishing diseñadas para engañar incluso a los usuarios más experimentados\n",
    "\n",
    "Esto nos lleva al meollo del asunto: ¿cómo aprovechamos el increíble poder de los LLMs mientras mitigamos los riesgos? La respuesta está en **prompt crafting**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Prompt Crafting: El Arte de Hablar con las Máquinas\n",
    "\n",
    "Hemos establecido que los LLMs son increíblemente buenos en predecir la siguiente palabra. Pero, ¿cómo aprovechamos esa habilidad para realmente *hacer* cosas? Aquí tienes una forma simple de pensarlo:\n",
    "\n",
    "> **Large Language Model Application = *Transformation Layer*** (entre el dominio del problema del usuario y el dominio del problema del LLM)\n",
    "\n",
    "En este escenario, la aplicación actúa como un intermediario entre el usuario y el LLM, manejando toda la complejidad involucrada en la creación del prompt adecuado y procesando la respuesta del modelo para proporcionar información valiosa o completar las tareas solicitadas.\n",
    "\n",
    "Vamos a explorar algunas técnicas específicas de prompt crafting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=groq_api_key,\n",
    ")\n",
    "\n",
    "def completion_groq(message, model=\"llama3-8b-8192\"):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"you are  a base language model that only predict word by word. Avoid any comment additional to make a completion.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": message,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "        temperature=1,\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "message = \"Explain the importance of fast language models\"\n",
    "response = completion_groq(message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Técnica 1: Few-Shot Prompting\n",
    "\n",
    "El avance de los LLMs no fue solo su tamaño; fue el descubrimiento de que realmente podíamos controlar su salida estructurando cuidadosamente la entrada. **Few-shot prompting** es un ejemplo perfecto de esto. Es como darle al LLM un curso intensivo en un nuevo tema proporcionando unos pocos ejemplos bien elegidos. Así es como funciona para una aplicación de traducción hipotética:\n",
    "\n",
    "```markdown\n",
    "> How are you doing today?\n",
    "< ¿Cómo estás hoy?\n",
    "> My name is John.\n",
    "< Mi nombre es John.\n",
    "> Can I have fries with that?\n",
    "```\n",
    "\n",
    "Le damos al modelo dos traducciones completas de inglés a español, estableciendo un patrón claro. Luego le presentamos una nueva oración en inglés. El LLM, entrenado para predecir la siguiente palabra, \"entiende\" que debe continuar el patrón y proporcionar la traducción al español de \"Can I have fries with that?\"\n",
    "\n",
    "Puntos clave sobre few-shot prompting:\n",
    "\n",
    "* **Simplicidad y Poder:** Es notablemente efectivo para dirigir las respuestas de los LLM hacia resultados deseados.\n",
    "* **Más allá de los Ejemplos:** El encabezado, la estructura e incluso el uso de construcciones de lenguaje familiares (como markdown) influyen en el comportamiento del LLM.\n",
    "* **El Contexto es Clave:** Cuanta más información relevante proporcionemos al principio, mayores serán las posibilidades del LLM de generar una respuesta útil.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puedo tener papas fritas con eso?\n"
     ]
    }
   ],
   "source": [
    "message = \"\"\"Q: How are you doing today?\n",
    "A: ¿Cómo estás hoy?\n",
    "Q: My name is John.\n",
    "A: Mi nombre es John.\n",
    "Q: Can I have fries with that?\n",
    "A:\"\"\"\n",
    "\n",
    "print(completion_groq(message))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Técnica 2: Chain of Thought Reasoning\n",
    "\n",
    "Aunque los LLMs sobresalen en tareas que implican fluidez en el lenguaje y reconocimiento de patrones, tradicionalmente han tenido dificultades con problemas que requieren razonamiento lógico o sentido común. Pregunta a un LLM temprano un problema matemático simple, y podrías obtener una respuesta sin sentido:\n",
    "\n",
    "```markdown\n",
    "P: A un panadero le lleva una hora hacer un pastel. ¿Cuánto tiempo tardan 3 panaderos en hacer 3 pasteles?\n",
    "R: 3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33 horas.\n"
     ]
    }
   ],
   "source": [
    "message = \"\"\"Q: A un panadero le lleva una hora hacer un pastel. ¿Cuánto tiempo tardan 3 panaderos en hacer 3 pasteles?\n",
    "A:\"\"\"\n",
    "\n",
    "print(completion_groq(message,model=\"gemma-7b-it\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Chain-of-thought reasoning** aborda esta limitación al pedir explícitamente al LLM que descomponga el problema en una serie de pasos lógicos. Es como mostrar tu trabajo en un examen de matemáticas, guiando al LLM hacia una solución más precisa. Así es como se ve en la práctica:\n",
    "\n",
    "```markdown\n",
    "P: Jim tiene el doble de la edad de Steve. Jim tiene 12 años, ¿cuántos años tiene Steve?\n",
    "R: En forma de ecuación: 12 = 2*a donde a es la edad de Steve. Dividiendo ambos lados por 2 vemos que a = 6. Steve tiene 6 años.\n",
    "P: A un panadero le lleva una hora hacer un pastel. ¿Cuánto tiempo tardan 3 panaderos en hacer 3 pasteles?\n",
    "R:\n",
    "```\n",
    "\n",
    "Al proporcionar un ejemplo trabajado, hemos dado al LLM un marco para abordar el segundo problema lógicamente. Una respuesta mucho más probable (y correcta) sería:\n",
    "\n",
    "```markdown\n",
    "P: Jim tiene el doble de la edad de Steve. Jim tiene 12 años, ¿cuántos años tiene Steve?\n",
    "R: En forma de ecuación: 12 = 2*a donde a es la edad de Steve. Dividiendo ambos lados por 2 vemos que a = 6. Steve tiene 6 años.\n",
    "P: A un panadero le lleva una hora hacer un pastel. ¿Cuánto tiempo tardan 3 panaderos en hacer 3 pasteles?\n",
    "R: Si cada panadero tarda 1 hora en hacer un pastel, entonces 3 panaderos tardarán 1 hora en hacer 3 pasteles\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hora.\n",
      "\n",
      "Cada panadero puede hacer un pastel en 1 hora, así que 3 panaderos pueden hacer 3 pasteles en 1 hora.\n"
     ]
    }
   ],
   "source": [
    "message = \"\"\"Q: Jim tiene el doble de la edad de Steve. Jim tiene 12 años, ¿cuántos años tiene Steve?\n",
    "A: En forma de ecuación: 12 = 2*a donde a es la edad de Steve. Dividiendo ambos lados por 2 vemos que a = 6. Steve tiene 6 años.\n",
    "Q: A un panadero le lleva una hora hacer un pastel. ¿Cuánto tiempo tardan 3 panaderos en hacer 3 pasteles?\n",
    "A:\"\"\"\n",
    "\n",
    "print(completion_groq(message, model=\"gemma-7b-it\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perspectivas Clave sobre Chain-of-Thought Prompting:**\n",
    "\n",
    "* <font color='blue'>**Reemplazando el Monólogo Interno:**</font> Los humanos razonan a través de problemas con diálogo interno. Los LLMs, por otro lado, dependen de la predicción de la siguiente palabra. Chain-of-thought prompting les obliga a externalizar ese proceso de razonamiento, llevando a resultados más lógicos.\n",
    "* <font color='green'>**Aprovechando el Attention Mechanism:**</font> El attention mechanism en los LLMs actúa como un \"espacio de trabajo\" donde estos pasos intermedios de razonamiento pueden ser expuestos y referenciados.\n",
    "* <font color='red'>**Previniendo el \"Sangrado\":**</font> Los ejemplos de few-shot pueden a veces \"sangrar\" en la salida, introduciendo sesgos no deseados. Podemos mitigar esto instruyendo explícitamente al LLM a \"pensar paso a paso\" en lugar de esperar que complete el patrón literalmente.\n",
    "* <font color='purple'>**La Concisión es Clave:**</font> Los LLMs tienen una ventana de contexto limitada. Las cadenas de pensamiento excesivamente largas pueden ser contraproducentes, ya que el modelo podría perder de vista el problema original.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero shot COT\n",
    "\n",
    "```\n",
    "Q: A un panadero le lleva una hora hacer un pastel. ¿Cuánto tiempo tardan 3 panaderos en hacer 3 pasteles?\n",
    "\n",
    "A: **Pensemos paso a paso**. *El tiempo que se tarda en hornear un pastel es el mismo sin importar cuántos pasteles se hagan y cuántas personas trabajen en ellos.\n",
    "Por lo tanto, la respuesta sigue siendo 1*\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hora. \n",
      "\n",
      "Si un panadero hace un pastel en una hora, 3 panaderos trabajan juntos pueden hacer 3 pasteles en la misma cantidad de tiempo.\n"
     ]
    }
   ],
   "source": [
    "# EJERCICIO 1: implementa el ejemplo de zero COT anterior usando la API de groq con el modelo gemma-7b-it y la función completion_groq.\n",
    "message = \"\"\"Q: A un panadero le lleva una hora hacer un pastel. ¿Cuánto tiempo tardan 3 panaderos en hacer 3 pasteles?\n",
    "A: **Pensemos paso a paso**. \"\"\"\n",
    "\n",
    "print(completion_groq(message, model=\"gemma-7b-it\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Técnica 3: Imitación de Documentos\n",
    "\n",
    "Imagina encontrar un trozo de papel rasgado con estas palabras:\n",
    "\n",
    "> <font color='yellow'>*My cable is out.  And I am going to miss the Super Bowl*</font>\n",
    "\n",
    "Incluso con un contexto limitado, puedes inferir mucho. Algo sucedió (corte de cable), llevando a una consecuencia negativa (perder el Super Bowl). Esta es la esencia de **document mimicry**. Los LLMs están entrenados en conjuntos de datos masivos de texto, código y otra información estructurada. Al imitar los formatos y convenciones de documentos comunes, podemos ayudar a los LLMs a \"entender\" el contexto de nuestros prompts y generar respuestas más relevantes.\n",
    "\n",
    "El LLM podría tener dificultades para proporcionar una respuesta útil. Pero, ¿qué pasa si estructuramos el prompt así:\n",
    "\n",
    "```markdown\n",
    "# IT Support Assistant\n",
    "The following is a transcript between an award-winning\n",
    "IT support rep and a customer.\n",
    "\n",
    "## Customer: \n",
    "My cable is out! And I'm going to miss the Super Bowl!\n",
    "\n",
    "## Support Assistant:\n",
    "```\n",
    "\n",
    "Al usar encabezados de markdown, un formato de transcripción e incluso un lenguaje cargado emocionalmente, hemos dado al LLM una comprensión mucho más rica de la situación. Ahora sabe:\n",
    "\n",
    "* <font color='blue'>**Tipo de Documento:**</font> Esta es una interacción de soporte al cliente\n",
    "* <font color='green'>**Estructura:**</font> Hay un diálogo claro entre un cliente y un agente de soporte\n",
    "* <font color='red'>**Contexto Emocional:**</font> El cliente está frustrado y necesita ayuda\n",
    "\n",
    "Esta información adicional aumenta significativamente las posibilidades de que el LLM genere una respuesta útil y empática.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Aquí tienes una comparación rápida de las técnicas que hemos cubierto:\n",
    "\n",
    "| Técnica | Descripción |\n",
    "| :--------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| Few-Shot Prompting | Ejemplos hechos a mano para \"entrenar\" al LLM a completar tareas similares |\n",
    "| Chain of Thought Prompting | Usa ejemplos de few-shot, pero el objetivo principal es guiar al modelo en los pasos a seguir para llegar a la respuesta correcta a problemas que implican lógica y razonamiento |\n",
    "| Document Mimicry | Usa elementos estructurales y formato textual de documentos comunes como transcripciones y markdown. El LLM, al estar entrenado en millones de documentos y códigos, debería ser capaz de entenderlos, mejorando sus capacidades para generar respuestas relevantes. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intuición para la Creación de Prompts: Los LLMs son Humanos Mecánicos Tontos.\n",
    "\n",
    "* Los LLMs entienden mejor cuando usas un lenguaje y construcciones familiares.\n",
    "* Los LLMs se distraen. No llenes el prompt con mucha información \"por si acaso\".\n",
    "* Los LLMs no son psíquicos. Si la información no está en el entrenamiento o en el prompt, entonces no la saben.\n",
    "* Si miras el prompt y no puedes entenderlo, un LLM es inútil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construyendo aplicaciones con LLMs\n",
    "\n",
    "<img style=\"width: 70%\" src=\"images/fig-14.png\" id=\"llm-app\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando el prompt\n",
    "\n",
    "* Recopilar contexto\n",
    "* Rankear contexto\n",
    "* Recortar contexto\n",
    "* Ensamblar el prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Creando el Prompt para la Compleción de Código**\n",
    "\n",
    "Apliquemos este concepto a un ejemplo más técnico: la compleción de código. Imagina un IDE (entorno de desarrollo integrado) potenciado por un LLM que ayuda a los desarrolladores a escribir código más rápido. Cuando un usuario solicita la compleción de código, el IDE no solo envía al LLM la línea de código actual. \n",
    "\n",
    "<img style=\"width: 70%\" src=\"images/fig-16.png\" id=\"llm-app\"/>\n",
    "\n",
    "Este prompt, estructurado como un archivo de código con comentarios, ayuda al LLM a \"entender\" la base de código y generar compleciones más relevantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### La introducción del Chat\n",
    "\n",
    "El lanzamiento de ChatGPT en noviembre de 2022 marcó un punto de inflexión significativo en la evolución de las aplicaciones de LLM. ChatGPT introdujo una nueva forma de interactuar con los LLMs, utilizando un formato conversacional y un lenguaje estructurado llamado ChatML.\n",
    "\n",
    "<img style=\"width: 70%\" src=\"images/fig-17.png\" id=\"llm-app\"/>\n",
    "\n",
    "Uno de los beneficios clave de ChatML es la capacidad de usar **system messages** para guiar el comportamiento del LLM y prevenir salidas indeseables. Las system messages son instrucciones del desarrollador que dictan el tono, estilo y parámetros de seguridad del asistente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La introducción de las Tools\n",
    "\n",
    "<img style=\"width: 70%\" src=\"images/fig-18.png\" id=\"llm-app\"/>\n",
    "\n",
    "El prompt anterior de ChatML define claramente los roles del usuario y del asistente, y ahora se introduce un nuevo elemento: `tool` o también llamado *function calling*. Aquí es donde entra en juego **function calling**. Los LLMs equipados con esta capacidad ahora pueden interactuar con herramientas y APIs externas, ampliando significativamente sus aplicaciones potenciales. En este ejemplo, el LLM reconoce la solicitud del usuario de información meteorológica y usa la función `get_weather` para recuperar los datos. La herramienta devuelve la temperatura (digamos 78 grados Fahrenheit), y el LLM incorpora esta información en su respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construyendo Aplicaciones con LLMs: Bags of Tools Agent\n",
    "\n",
    "<img style=\"width: 70%\" src=\"images/fig-19.png\" id=\"llm-app\"/>\n",
    "\n",
    "\n",
    "<img style=\"width: 70%\" src=\"images/fig-20.png\" id=\"llm-app\"/>\n",
    "\n",
    "Esto destaca un punto crucial: **incluso con function calling, la aplicación sigue siendo la capa de transformación.** Es responsable de mediar entre la intención del usuario, las capacidades del LLM y el mundo exterior, asegurando interacciones seguras y apropiadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips para definir las Tools\n",
    "\n",
    "* No tengas \"demasiadas\" tools - busca evidencia de colisiones\n",
    "\n",
    "* Nombra las tools de forma simple y clara (¿y en formato TypeScript?)\n",
    "\n",
    "* No copies/pegues tu API - mantén los argumentos simples y pocos\n",
    "\n",
    "* Mantén cortas las descripciones de la función y los argumentos y considera lo que el modelo\n",
    "sabe\n",
    "    - Probablemente entiende la documentación pública.\n",
    "    - No conoce los acrónimos internos de la empresa.\n",
    "\n",
    "* Más sobre los argumentos\n",
    "    - Los argumentos anidados no retienen las descripciones\n",
    "    - Puedes usar enum y default, pero no minimum, maximum...\n",
    "    \n",
    "* Salida de la habilidad – no incluyas contenido extra \"por si acaso\"\n",
    "* Errores de la habilidad – cuando sea razonable, envía errores al modelo (errores de validación)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Conclusiones Clave de ChatGPT y Function Calling:**\n",
    "\n",
    "* **ChatML:** Un lenguaje estructurado para construir aplicaciones conversacionales con LLM, facilitando la definición de roles, el control del flujo y la gestión del contexto.\n",
    "* **Function Calling:** Permite que los LLMs interactúen con herramientas y APIs externas, ampliando significativamente sus aplicaciones prácticas.\n",
    "* **System Messages:** Permiten a los desarrolladores imponer directrices de seguridad, establecer el tono del asistente y prevenir salidas no deseadas.\n",
    "* **Capa de Transformación:** A pesar de estos avances, la aplicación sigue jugando un papel vital en la traducción entre las necesidades del usuario y las capacidades del LLM, asegurando un uso responsable y ético.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Una Perspectiva Más Amplia sobre Técnicas de Prompt Engineering\n",
    "\n",
    "Aunque las técnicas que hemos discutido proporcionan una base sólida, es esencial reconocer el panorama más amplio del prompt engineering:\n",
    "\n",
    "* **Zero-Shot Prompting:** Proporcionar al LLM una descripción de la tarea y esperar que la realice sin ningún ejemplo. Sorprendentemente efectivo para algunas tareas como la summarization.\n",
    "* **One-Shot Prompting:** Similar al zero-shot, pero con un solo ejemplo proporcionado.\n",
    "* **Instruction Prompting:** Guiar al LLM para que responda en un tono, persona, longitud o formato específico.\n",
    "\n",
    "\n",
    "Recuerda, estas técnicas están en constante evolución junto con la tecnología de los LLM. Lo que hoy parece innovador, mañana podría ser común.\n",
    "\n",
    "[https://www.promptingguide.ai/](https://www.promptingguide.ai/) es una guía de ing. de prompts con múltiples técnicas. Es recomendable su lectura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusión\n",
    "\n",
    "El prompt crafting es tanto un arte como una ciencia. Al entender las fortalezas y limitaciones de los LLMs, y al aprovechar técnicas como few-shot prompting, chain-of-thought reasoning, document mimicry, y el poder de ChatML y function calling, podemos desbloquear el potencial transformador de esta tecnología mientras navegamos por las consideraciones éticas de manera responsable.\n",
    "\n",
    "El futuro de la IA depende de nuestra capacidad para comunicarnos eficazmente con estas poderosas máquinas, guiándolas hacia un futuro que beneficie a toda la humanidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructuración de salidad en modo JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"message\": \"Hola! Estoy funcionando correctamente, gracias por preguntar.\",\n",
      "\"status\": \" Bien\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def chat_groq(user, system=\"you are a helpful assistant\",  model=\"llama3-8b-8192\", temperature=1, **kwargs):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "print(chat_groq(system=\"eres un asistente que siempre habla en español y que responde en formato JSON\",\n",
    "                 user=\"hola como estas?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"english_words\": [\"prompt\", \"crafting\", \"LLMs\", \"few-shot\", \"prompting\", \"chain-of-thought\", \"reasoning\", \"document\", \"mimicry\", \"ChatML\", \"function\", \"calling\", \"transformador\", \"IA\"]}\n"
     ]
    }
   ],
   "source": [
    "texto = \"El prompt crafting es tanto un arte como una ciencia. Al \\\n",
    "    entender las fortalezas y limitaciones de los LLMs, y al aprovechar técnicas como few-shot prompting,\\\n",
    "          chain-of-thought reasoning, document mimicry, y el poder de ChatML y function calling,\\\n",
    "              podemos desbloquear el potencial transformador de esta tecnología mientras navegamos\\\n",
    "                  por las consideraciones éticas de manera responsable.\\\n",
    "                    El futuro de la IA depende de nuestra capacidad para comunicarnos eficazmente\\\n",
    "                          con estas poderosas máquinas, guiándolas hacia un futuro que beneficie a toda la humanidad.\"\n",
    "\n",
    "respuesta = chat_groq(\n",
    "            system=\"\"\"extrae las palabras en inglés del texto. Genera la respuesta en un formato JSON\n",
    "            de la forma:\n",
    "            ```json\n",
    "            {\"english_words\": [\"word1\", \"word2\", ...]}\n",
    "            ```\"\"\",\n",
    "            user=f\"Este es el texto: {texto}\",\n",
    "            model=\"llama3-70b-8192\",\n",
    "            temperature=0\n",
    "        )\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Calling en Groq (con nuevos modelos, es muy reciente!)\n",
    "\n",
    "Es un ejemplo que está en la [documentación de groq](https://console.groq.com/docs/tool-use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting conversation with user prompt: What is 25 * 4 + 10?\n",
      "\n",
      "Initial messages: [{'role': 'system', 'content': 'You are a calculator assistant. Use the calculate function to perform mathematical operations and provide the results.'}, {'role': 'user', 'content': 'What is 25 * 4 + 10?'}]\n",
      "\n",
      "First Response message: ChoiceMessage(content=None, role='assistant', tool_calls=[ChoiceMessageToolCall(id='call_8veg', function=ChoiceMessageToolCallFunction(arguments='{\"expression\": \"25*4+10\"}', name='calculate'), type='function')])\n",
      "\n",
      "Messages after tool calls: [{'role': 'system', 'content': 'You are a calculator assistant. Use the calculate function to perform mathematical operations and provide the results.'}, {'role': 'user', 'content': 'What is 25 * 4 + 10?'}, ChoiceMessage(content=None, role='assistant', tool_calls=[ChoiceMessageToolCall(id='call_8veg', function=ChoiceMessageToolCallFunction(arguments='{\"expression\": \"25*4+10\"}', name='calculate'), type='function')]), {'tool_call_id': 'call_8veg', 'role': 'tool', 'name': 'calculate', 'content': '{\"result\": 110}'}]\n",
      "\n",
      " The result of 25 * 4 + 10 is 110.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import json\n",
    "\n",
    "client = Groq()\n",
    "MODEL = 'llama3-groq-70b-8192-tool-use-preview'\n",
    "\n",
    "def calculate(expression):\n",
    "    \"\"\"Evaluate a mathematical expression\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return json.dumps({\"result\": result})\n",
    "    except:\n",
    "        return json.dumps({\"error\": \"Invalid expression\"})\n",
    "\n",
    "def run_conversation(user_prompt, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"Starting conversation with user prompt:\", user_prompt)\n",
    "        \n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a calculator assistant. Use the calculate function to perform mathematical operations and provide the results.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nInitial messages:\", messages)\n",
    "        \n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"calculate\",\n",
    "                \"description\": \"Evaluate a mathematical expression\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The mathematical expression to evaluate\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"expression\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "        max_tokens=4096\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    if verbose:\n",
    "        print(\"\\nFirst Response message:\", response_message)\n",
    "    tool_calls = response_message.tool_calls\n",
    "    if tool_calls:\n",
    "        available_functions = {\n",
    "            \"calculate\": calculate,\n",
    "        }\n",
    "        messages.append(response_message)\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                expression=function_args.get(\"expression\")\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )\n",
    "        if verbose:\n",
    "            print(\"\\nMessages after tool calls:\", messages)\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages\n",
    "        )\n",
    "        return second_response.choices[0].message.content\n",
    "\n",
    "user_prompt = \"What is 25 * 4 + 10?\"\n",
    "print(\"\\n\",run_conversation(user_prompt, verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La lógica del código anterior en el contexto de function calling o tools:\n",
    "\n",
    "1. Se hace una llamada inicial al modelo, proporcionando los mensajes, las herramientas disponibles (`tools`), y configurando `tool_choice=\"auto\"`. Esto permite al modelo decidir si necesita usar una herramienta.\n",
    "\n",
    "2. Se extrae el mensaje de respuesta y, si hay llamadas a herramientas (`tool_calls`), se procede a ejecutarlas.\n",
    "\n",
    "3. Se define un diccionario `available_functions` que mapea el nombre de la función (\"calculate\") a la función Python real.\n",
    "\n",
    "4. Para cada llamada a herramienta:\n",
    "   - Se obtiene el nombre de la función y los argumentos.\n",
    "   - Se ejecuta la función correspondiente con los argumentos proporcionados.\n",
    "   - Se añade la respuesta de la función a la lista de mensajes.\n",
    "\n",
    "5. Después de ejecutar todas las llamadas a herramientas, se hace una segunda llamada al modelo, incluyendo los resultados de las herramientas en los mensajes.\n",
    "\n",
    "6. Finalmente, se devuelve el contenido del mensaje de esta segunda respuesta.\n",
    "\n",
    "Esta implementación permite al modelo:\n",
    "1. Reconocer cuando necesita realizar un cálculo.\n",
    "2. Solicitar la ejecución de la función `calculate`.\n",
    "3. Recibir el resultado del cálculo.\n",
    "4. Usar ese resultado para formular una respuesta final al usuario.\n",
    "\n",
    "Es un ejemplo claro de cómo el function calling o tools permiten a los modelos de lenguaje interactuar con funciones externas para realizar tareas específicas, en este caso, cálculos matemáticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AB2024_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
